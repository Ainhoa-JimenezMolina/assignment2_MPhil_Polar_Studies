---
title: "NDVI"
author: "Ainhoa"
date: "2025-01-04"
output: html_document
editor_options: 
  chunk_output_type: inline
  markdown: 
    wrap: 72
---

Script with coarser aspect data and more comparisons EVI-NDVI

### 1. Set working directory

```{r}
setwd("~/Library/CloudStorage/OneDrive-UniversityofCambridge/Intro to cambridge/Practicals/assignment2")
```

### 2. Dowload necessary packages

```{r libraries, message=FALSE}
# Install packages if not already installed
#install.packages("raster")
#install.packages("rgdal")
#install.packages("mblm") # Install if you don't have it already
#install.packages("Kendall")
#install.packages("openxlsx")

# Load the necessary libraries
library(raster)
library(rgdal)
library(dplyr)
library(tidyverse)
library(performance) #check models
library(mblm) # conduct Theil-Sen regression
library(lme4) # AICc
library(MuMIn) # AICc
library(Kendall) # Mann-Kendall test --> signifcance of slope
library(maps) # create maps
library(ggspatial) # create maps
library(broom) # for table
library(kableExtra) # For prettier tables
library(openxlsx) # write excel table
```

### 3. Load the data

```{r}
data_NDVI<- read.csv("NDVIExportCoordinates.csv")
data_elevation <- read.csv("ElevationExportCoordinates.csv")
data_aspect <- read.csv("AspectExportCoordinates2000.csv")
data_distance <- read.csv("distanceToSeaCollection.csv")
data_NDVI_predictions <- read.csv("samplesPredictions.csv")
data_EVI_predictions <- read.csv("samplesPredictions_evi.csv")

```

Explore data

```{r}
summary(data_NDVI)
summary(data_aspect)
summary(data_elevation)
summary (data_distance) # distance to sea is in meters
summary(data_NDVI_predictions)
summary(data_EVI_predictions)
```

Clean data aspect --\> turn aspect into a factor and add labels

```{r}
data_aspect$aspect <- factor(data_aspect$aspect, levels = c(1,2,3,4),
                               labels = c("north", "south", "east", "west"))
# north = 1
# South = 2
# East = 3
# West = 4

summary(data_aspect$aspect)

```

Clean distance--\> make the same system index as the rest

```{r}
# Adding "_0" to each value in the 'system.index' column
data_distance <- data_distance %>%
  mutate(system.index = str_c(system.index, "_0"), # str_c from the stringr package
         distance_to_sea_corrected = distance_to_sea + 10) # the real coast is 10 m further away--> it is the buffer I used to create the coastline
```

#### 3.2. Put all in the same dataset

```{r}
#Start with dem (same number of observations)
full_data_dem <- inner_join(data_elevation,data_aspect, by = c("system.index")) %>% 
  select(- c(latitude.y, longitude.y)) %>%  #keep latitude and longitude elevation
  rename(latitude = latitude.x,
         longitude = longitude.x)


full_data <- inner_join(full_data_dem, data_NDVI, by =c("system.index"))
# Latitude and longitude between DEM and NDVI are the same up to the third decimal. Then change slightly because of the scaling. We are taking one (the NDVI one) and ignoring the other one. 
# Distance doesn't have coordinates data

full_data <- inner_join(full_data, data_distance, by =c("system.index"))

# Format data and remove columns I don't need
full_data <- full_data %>% 
  select(-c(".geo.x",".geo.y", "latitude.x","longitude.x", ".geo.y.y", ".geo.x.x")) %>% 
  rename(latitude = latitude.y,
         longitud = longitude.y)
```

### 3.2. Create map with all sample locations

```{r}
# Base world map data
(world_map <- map_data("world"))

# Create the map focused on West Greenland
(map_samples <- ggplot() +
  # Add the world map as a base layer
  geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = "gray90", color = "gray50") +
  # Add the data points
  geom_point(data = data_NDVI, aes(x = longitude, y = latitude), color = "red", size = 1.2, alpha = 0.7) +
  # Customize the map
  labs(
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 14, face = "bold"),  # Larger and bold axis titles
    axis.text = element_text(size = 12),                 # Larger axis text
    plot.title = element_text(size = 16, face = "bold")  # Larger and bold plot title
  ) +
  coord_quickmap(xlim = c(-73, -35), ylim = c(60, 83)) +  # Focus on West Greenland
  annotation_north_arrow(location = "tr", which_north = "true", style = north_arrow_fancy_orienteering()))

ggsave(filename = "figures/map_samples.png", map_samples, width = 20,height = 20, units = "cm", device = "png")  # Save graph

```

World map

```{r}
# Load world map data
world_map <- map_data("world")

# Create the map using ggplot2
world_map_figure <- ggplot(data = world_map, aes(x = long, y = lat, group = group)) +
  geom_polygon(fill = "gray90", color = "gray50") + # Map polygons with color and border
  theme_minimal() + # Apply a minimal theme
    theme(
    axis.title = element_text(size = 14, face = "bold"),  # Larger and bold axis titles
    axis.text = element_text(size = 12),                 # Larger axis text
    plot.title = element_text(size = 16, face = "bold")  # Larger and bold plot title
  ) +
    coord_quickmap(xlim = c(-150, +180)) +  # Focus on West Greenland
  annotation_north_arrow(location = "tr", which_north = "true", style = north_arrow_fancy_orienteering())+
  labs( x = "Longitude", y = "Latitude")

ggsave(filename = "figures/world_map_figure.png", world_map_figure, width = 20,height = 10, units = "cm", device = "png")  # Save graph
```

### 4. Check EVI vs NDVI

#### 1. Load data

```{r}
data_EVI_NDVI <- read.csv("data_compare_EVI_NDVI.csv")

# Keep only columns that I need
data_EVI_NDVI_clean <- data_EVI_NDVI %>% 
  select(c(EVI, NDVI)) %>% 
  mutate(EVI_scale = EVI/10000) # EVI is supposed to have -1 to 1 values
```

#### 2. Check the relationship

##### 1. Try with data compare EVI and NDVI--\> sample 13 random location in 200 random pictures

```{r}
(plot_EVI_NDVI <- data_EVI_NDVI_clean %>% 
  ggplot(aes(x = NDVI, y = EVI_scale)) +
  geom_point() +
  geom_smooth() +
  geom_abline(aes(intercept = 0, slope = 1)) +
   labs(x = "NDVI",
        y = "EVI") +
  theme_classic() )
```

##### 2. Try with max yearly NDVI and EVI values --\>1000 samples of 9 years of data (max NDVI and EVI for each year from 2015 to 2024)--\> 9000 points

Clean and merge data

```{r}
# Rename columns correctly
data_EVI_predictions <- data_EVI_predictions %>% 
  rename(EVI = NDVI,
         sensPredictions_EVI = sensPredictions)

data_NDVI_predictions <- data_NDVI_predictions %>% 
  rename(sensPredictions_NDVI = sensPredictions)

# Merge NDVI and EVI datasets

data_EVI_NDVI_predictions <- inner_join(data_NDVI_predictions, data_EVI_predictions, by = c("system.index", "longitude", "latitude", "yearOffset")) %>% 
  select(-c("Constant.x", ".geo.x", "Constant.y", ".geo.y")) %>% 
  mutate(EVI_scale = EVI/10000)
```

Compare one and the other

```{r}
(plot_EVI_NDVI <- data_EVI_NDVI_predictions %>% 
  ggplot(aes(x = NDVI, y = EVI_scale)) +
  geom_point() +
  geom_smooth() +
  geom_abline(aes(intercept = 0, slope = 1)) +
   labs(x = "NDVI",
        y = "EVI") +
  theme_classic() )
```

Pasa lo mismo en los ods casos. There is a range of values in NDVI=0
that goes all around the EVI axis and viceversa

```{r}
#pearson correlation

cor(data_EVI_NDVI_predictions$NDVI, data_EVI_NDVI_predictions$EVI, method = "pearson")
cor(data_EVI_NDVI_clean$NDVI, data_EVI_NDVI_clean$EVI, method = "pearson")
```

No association. However, contrary to expected, it doesn't seem like the
NDVI is saturating, but more like there is a discrepancy between both
methods.

\#####***THE EVI IS WRONG ABOVE â€“\> NEED TO RECALCULATE***

Use NDVI

8th January---- The correlation should be higher. Comparing max NDVI and
Max EVI doesn't work--\> you are not comparing same pixel same time so
tehre is no correlation necessarily. Try 2nd time with random images
with more samples and a different equation and removing -0.2 10th
January ---- The range of values is low. Add two more datasets to get
more datapoints and increase range

```{r}
data_EVI_NDVI_1 <- read.csv("data_compare_EVI_NDVI_try2.csv")
data_EVI_NDVI_2 <- read.csv("data_compare_EVI_NDVI2.csv")
data_EVI_NDVI_3 <- read.csv("data_compare_EVI_NDVI3.csv")
data_EVI_NDVI_4 <- read.csv("data_compare_EVI_NDVI4.csv")

data_EVI_NDVI_combined <- bind_rows(data_EVI_NDVI_1, data_EVI_NDVI_2,data_EVI_NDVI_3,data_EVI_NDVI_4 )

# remove values < 0.2
data_EVI_NDVI_combined_clean <- data_EVI_NDVI_combined %>% 
  filter(EVI >= 0.2,
         NDVI >= 0.2)
# 230 observations

# Check max NDVI values

(data_max<- data_EVI_NDVI_combined_clean %>% 
  filter(NDVI > 0.6))
```

```{r}
(plot_EVI_NDVI <- data_EVI_NDVI_combined_clean %>% 
  ggplot(aes(x = EVI, y = NDVI)) +
  geom_point() +
  geom_smooth() +
  geom_abline(aes(intercept = 0, slope = 1)) +
   labs(x = "\nEVI",
        y = "NDVI") +
  theme_classic()+
   theme(
    axis.title = element_text(size = 14, face = "bold"),  # Larger and bold axis titles
    axis.text = element_text(size = 12),                 # Larger axis text
  ) )

ggsave(filename = "figures/EVI_NDVI_comparison.png", plot_EVI_NDVI, width = 20,height = 15, units = "cm", device = "png")  # Save graph
```

```{r}
cor(data_EVI_NDVI_combined_clean$NDVI, data_EVI_NDVI_combined_clean$EVI, method = "pearson")
```

Strong correlation (0.849) and no saturation in the graph. Can proceed
with NDVI

### 5. Test significance of the slope of NDVI

```{r}

# adapt and clean data
data_NDVI_predictions_clean <- data_NDVI_predictions %>%
  mutate(year = (ceiling(yearOffset) + 2015)) %>%  # rounded up the offset (difference) and added it to 2015
  select(-c("Constant", ".geo"))

# Check
unique(data_NDVI_predictions_clean$yearOffset) # right values (10)<-- need to find the conversion
unique(data_NDVI_predictions_clean$year)

# inspect data

summary_NDVI_predictions_loc <- data_NDVI_predictions_clean %>% 
  group_by(latitude, longitude) %>%
  summarise (n = n())

unique(summary_NDVI_predictions_loc$n)

summary_NDVI_predictions_year <- data_NDVI_predictions_clean %>% 
  group_by(year) %>%
  summarise (n = n()) # each year has 1074 data points (one per location) except 2015 --> why?

summary_yearOffset <-data_NDVI_predictions %>%
  group_by(yearOffset) %>% 
  summarise(n=n()) # each offset has 1074 data points (one per location) except 2015 --> why?--> is something in google earth engine--> maybe not data for that year for all locations
```

```{r}
# Create function

MannKendalltest <- function(data){
  MannKendall(data$NDVI)
}

# Group by location (each location a different latitude and longitude) and apply

MannkendallResults <- data_NDVI_predictions_clean %>%
  group_by(latitude, longitude) %>%
  summarise(test_result = list(MannKendalltest(cur_data()))) # cur_data() gets the current group

MannkendallResults
view(MannkendallResults[1,3])

#data_location1<- data_NDVI_predictions_clean %>% 
#    mutate(latitude = round(latitude, 4),
#         longitude = round(longitude, 4)) %>% 
#  filter(latitude == 59.8473,
#         longitude == -44.0573)


#MannKendall(data_location1$NDVI) 

```

Rearrange data so it is easily accessible

```{r}
# Separate into different columns
MannkendallResults_read <- separate_wider_delim(MannkendallResults, test_result,",",names = c("tau", "sI", "S", "D", "varS") ) # sl is the p value

# Clean unnecessary characters in each column
MannkendallResults_read$tau <- gsub("list\\(tau =","", MannkendallResults_read$tau)
MannkendallResults_read$sI <- gsub(" sl =" ,"", MannkendallResults_read$sI)
MannkendallResults_read$S <- gsub(" S =" ,"", MannkendallResults_read$S)
MannkendallResults_read$D <- gsub(" D =" ,"", MannkendallResults_read$D)
MannkendallResults_read$varS <- gsub("varS = " ,"", MannkendallResults_read$varS)
MannkendallResults_read$varS <- gsub(")" ,"", MannkendallResults_read$varS)

MannkendallResults_read<- MannkendallResults_read %>% 
  mutate(tau = as.numeric(tau),
         sI = as.numeric(sI),
         S = as.numeric(S),
         D = as.numeric(D),
         varS =as.numeric(varS))
```

```{r}
# filter for significant slopes

MannkendallResults_significant <- MannkendallResults_read %>% 
  filter(sI <= 0.05)

# Trend significnat in 160 ocations --> what % is that

(percentage_significant <- 160/ 1074*100)

```

The trend is significnat in 160 locations (14. 89 %)

```{r}
# differentiate between greening or browning

# add slope
MannkendallResults_significant <- inner_join(MannkendallResults_significant, data_NDVI, by = c("latitude", "longitude")) 

# add trend direction
MannkendallResults_significant <- MannkendallResults_significant %>% 
  mutate(Trend = case_when(
    slope < 0 ~ "Browning",
    slope == 0 ~ "No trend",
    slope > 0 ~ "Greening"
  ))

# count differences

MannkendallResults_significant_trends <- MannkendallResults_significant %>% 
  group_by(Trend) %>% 
  summarise (n = n())

MannkendallResults_significant_trends

# Percentage greening and brwning

(percentage_browning <- 13/1074*100)
(percentage_greening <- 147/1074*100)

```

Vast majority of significant trends were greening

#### 5.2. create map with significant locations

Create a map

```{r}
# Base world map data
(world_map <- map_data("world"))

# Create the map focused on West Greenland
(map_significant_samples <- ggplot() +
  # Add the world map as a base layer
  geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = "gray90", color = "gray50") +
  # Add the data points
  geom_point(data = MannkendallResults_significant, aes(x = longitude, y = latitude), color = "blue", size = 1, alpha = 0.7) +
  # Customize the map
  labs(
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 14, face = "bold"),  # Larger and bold axis titles
    axis.text = element_text(size = 12),                 # Larger axis text
    plot.title = element_text(size = 16, face = "bold")  # Larger and bold plot title
  ) +
  coord_quickmap(xlim = c(-73, -20), ylim = c(60, 83)) +  # Focus on West Greenland
  annotation_north_arrow(location = "tr", which_north = "true", style = north_arrow_fancy_orienteering()))


```

Create a map with the trend

```{r}
# Base world map data
(world_map <- map_data("world"))

# Create the map focused on West Greenland
(map_significant_samples_trend <- ggplot() +
  # Add the world map as a base layer
  geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = "gray90", color = "gray50") +
  # Add the data points
  geom_point(data = MannkendallResults_significant, aes(x = longitude, y = latitude, color = Trend, shape = Trend), size = 1.3, alpha = 0.9) +
  # Adjust colors
    scale_color_manual(
    values = c("Greening" = "darkgreen", "Browning" = "darkorange"),  # Map trends to colors
    name = "Trend"                                           # Legend title
  ) +
    # Adjust shapes
  scale_shape_manual(
    values = c("Greening" = 16, "Browning" = 17),  # Circles for greening, triangles for browning
    name = "Trend"  # Legend title
  ) +
  # Customize the map
  labs(
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 14, face = "bold"),  # Larger and bold axis titles
    axis.text = element_text(size = 12),                 # Larger axis text
    plot.title = element_text(size = 16, face = "bold"),  # Larger and bold plot title
    legend.title = element_text(size = 14, face = "bold"), # Larger and bold legend title
    legend.text = element_text(size = 12),  # Larger legend text
  ) +
  coord_quickmap(xlim = c(-73, -35), ylim = c(60, 83)) +  # Focus on West Greenland
  annotation_north_arrow(location = "tr", which_north = "true", style = north_arrow_fancy_orienteering()))

ggsave(filename = "figures/map_significant_samples_trend.png", map_significant_samples_trend, width = 20,height = 20, units = "cm", device = "png")  # Save graph

```

## TOPOGRAPHIC FACTORS AND TRENDS- ALL SAMPLE POINTS

1.  Filter data to values of NDVI \>0.2c--\> no los tengo

```{r}
#full_data_filtered <- full_data %>% 
#  filter(NDVI >= 0.2)
```

### 5. Check if I can do a lm

1.  It has a normal distribution

```{r}
(histogram_slope <- ggplot(data = full_data) +
  geom_histogram(aes(x = slope), bins = 30, fill = "blue", color = "black", alpha = 0.7))
```

### 6. Check slope change:

```{r}
# see if slope changes with elevation
lm_elevation <- lm(slope ~ elevation, data = full_data )
summary(lm_elevation)


# Check if model fits
elevation_resids <- resid(lm_elevation)
shapiro.test(elevation_resids)

check_model(lm_elevation)
# Residuals are not normally distributed

lm_elevation_log <- lm(slope ~ log(elevation), data = full_data)
check_model(lm_elevation_log)
#doesn't make it better + it adds NAs

# Non-parametric alternative --> Theil-Sen
ts_lm_elevation <- mblm(slope ~ elevation,data = full_data)
summary(ts_lm_elevation)
```

it changes significantly with altitude (p\<0.05) and the hhigher the
elevation the more negative the slope: browning more likely in higher
elevations.

However, it explains very little of teh variation of slopes(8%)

```{r}
# see if slope changes with latitude
lm_latitude <- lm(slope ~ latitude, data = full_data )
summary(lm_latitude)
```

Non-significant and changes nothing

```{r}
# see if slope changes with distance to sea
lm_distance_sea <- lm(slope ~ distance_to_sea, data = full_data )
summary(lm_distance_sea)

ts_lm_distance_sea <- mblm(slope ~ distance_to_sea, data = full_data )
summary(ts_lm_distance_sea)

AICc(ts_lm_elevation, ts_lm_distance_sea)
```

It does. The furthers from the coast, the more likely browning is. (p\<
0.05) It explains very little (2%).

**it is possible that distance and elevation correlate with each other.
That the further you are from the coast you are more likely to be up**

```{r}
#see change with aspect

lm_aspect <- lm(slope ~ aspect, data = full_data )
anova(lm_aspect)
summary(lm_aspect)

### No effect with all aspects

# See just between north and south --> less samples but still enough (587)

data_north_south <- full_data %>% 
  filter(aspect %in% c("north", "south") 
         
         )
lm_aspect_ns <- lm(slope ~ aspect, data = data_north_south )
anova(lm_aspect_ns)
summary(lm_aspect_ns)

```

Aspect has no significant effect

## TOPOGRAPHIC FACTORS AND TRENDS- ONLY SIGNIFICANT SAMPLE POINTS

### 1. create the data set you are going to use

```{r}
# Cleaning data
data_models_significant <- MannkendallResults_significant %>% 
  select(-c("D", "S", "varS", ".geo"))

# adding topographic data
data_models_significant <- inner_join(data_models_significant, full_data, by = c("system.index", "offset", "slope"))

# there are missing samples which we don't have topographic data for. See which ones there are
missing_index <- setdiff(MannkendallResults_significant$system.index, data_models_significant$system.index)

missing_index

# cleaning data again - retain latitude and longitude from the first dataset
data_models_significant <- data_models_significant %>% 
  select(-c("latitude.y", 
            "longitud"))%>% 
  rename( latitude = latitude.x)

```

### 2. Check if I can use linear model

```{r}
(histogram_slope <- ggplot(data = data_models_significant) +
  geom_histogram(aes(x = slope), bins = 30, fill = "blue", color = "black", alpha = 0.7))
```

### 3. Check slope change:

```{r}
# see if slope changes with elevation
lm_elevation_s <- lm(slope ~ elevation, data = data_models_significant )
summary(lm_elevation_s)


# Check if model fits
elevation_resids_s <- resid(lm_elevation_s)
shapiro.test(elevation_resids_s)

check_model(lm_elevation_s)

# Non-parametric alternative --> Theil-Sen
ts_lm_elevation_s <- mblm(slope ~ elevation,data = data_models_significant)
summary(ts_lm_elevation_s)
```

I think lm is good enough--\> use lm Elevation effect is significant
--\> with 1 m elevation increase the slope is reduced. Explains 13% of
variation of slopes

```{r}
# see if slope changes with latitude
lm_latitude_s <- lm(slope ~ latitude, data = data_models_significant )
summary(lm_latitude_s)

# Check if model fits
latitude_resids_s <- resid(lm_latitude_s)
shapiro.test(latitude_resids_s)

check_model(lm_latitude_s)

# Non-parametric alternative --> Theil-Sen
ts_lm_latitude_s <- mblm(slope ~ latitude, data = data_models_significant)
summary(ts_lm_latitude_s)
```

Significant. The higher the latitude, the more likely it is that there
is browning. But very small effect (only 4 %)

```{r}

# see if slope changes with distance to sea
lm_distance_sea_s <- lm(slope ~ distance_to_sea_corrected, data = data_models_significant )
summary(lm_distance_sea_s)

# Check if model fits
distance_sea_resids_s <- resid(lm_latitude_s)
shapiro.test(distance_sea_resids_s)

check_model(lm_distance_sea_s)

# Non-parametric alternative-->  Theil-Sen model
ts_lm_distance_sea_s <- mblm(slope ~ distance_to_sea_corrected, data = data_models_significant )
summary(ts_lm_distance_sea_s)

```

Significant. Explains very little 2%. The further away from the sea, the
more likely browning is. Maybe there is a correlation between elevation
and distance to sea--\> further away from the sea also higher (if there
is we will see in the model)

```{r}
#see change with aspect

lm_aspect_s <- lm(slope ~ aspect, data = data_models_significant)
anova(lm_aspect_s)
summary(lm_aspect_s)

# Check if model fits
aspect_resids_s <- resid(lm_aspect_s)
shapiro.test(aspect_resids_s)

check_model(lm_aspect_s)

# Non-parametric alternative--> yoy can't do Theil-Sen model because you are working with factors --> Kruskal-Wallis
kw_lm_aspect_s <- kruskal.test(slope ~ aspect, data = data_models_significant)
print(kw_lm_aspect_s)

### No effect with all aspects

# See just between north and south --> less samples but still enough (82)

data_north_south_significant <- data_models_significant %>% 
  filter(aspect %in% c("north", "south"))

lm_aspect_ns_s <- lm(slope ~ aspect, data = data_north_south_significant)
anova(lm_aspect_ns_s)
summary(lm_aspect_ns_s)

# Check if model fits
aspect_resids_ns_s <- resid(lm_aspect_ns_s)
shapiro.test(aspect_resids_ns_s)

check_model(lm_aspect_ns_s)

# Non-parametric alternative--> yoy can't do Theil-Sen model because you are working with factors --> Kruskal-Wallis
kw_lm_aspect_ns_s <- kruskal.test(slope ~ aspect, data = data_north_south_significant)
print(kw_lm_aspect_ns_s)

```

No significant effect of aspect in any case. Shapiro says normal data

Weird--\> check aspect data

```{r}
data_aspect_analyse <- data_models_significant %>% 
  group_by(aspect) %>% 
  summarise(n=n())

data_aspect_analyse
# pretty equitative
```

16th Jan - try interaction with latitude

```{r}
lm_aspect_elevation_s <- lm(slope ~ elevation* aspect, data = data_models_significant)
anova(lm_aspect_elevation_s)
summary(lm_aspect_elevation_s) # no significant

check_model(lm_aspect_elevation_s)
```

Boxplot

```{r}
(boxplot_aspect<- data_models_significant %>% 
  ggplot()+
  geom_boxplot(aes(x= aspect, y= slope, color = aspect, show.legend = FALSE))+
    labs(x = "Aspect",
       y = "Slope of the trend\n") +
     # Adjust colors
    scale_color_manual(
    values = c("north" = "tomato", "south" = "#1E90FF", east = "lightgreen", west = "purple"),  # Map trends to colors
    name = "Aspect"  )+                                         # Legend title)
  theme_classic()+
  theme(
    axis.title = element_text(size = 14, face = "bold"),  # Larger and bold axis titles
    axis.text = element_text(size = 12),                 # Larger axis text
    legend.title = element_blank(), # Larger and bold legend title
    legend.text = element_blank(),
    legend.position = "none"))

# Save graph
ggsave(filename = "figures/boxplot_aspect.png", boxplot_aspect, width = 15,height = 10, units = "cm", device = "png")

(boxplot_aspect_ns<- data_north_south_significant %>% 
  ggplot()+
  geom_boxplot(aes(x= aspect, y= slope, color = aspect, show.legend = FALSE))+
    labs(x = "Aspect",
       y = "Slope of the trend\n") +
         # Adjust colors
 scale_color_manual(
    values = c("north" = "#FF6347", "south" = "#1E90FF"),  # Map trends to colors
    name = "Aspect"  )+ 
  theme_classic()+
  theme(
    axis.title = element_text(size = 14, face = "bold"),  # Larger and bold axis titles
    axis.text = element_text(size = 12),                 # Larger axis text
    legend.title = element_blank(), # Larger and bold legend title
    legend.text = element_blank(),
    legend.position = "none"))

# Save graph
ggsave(filename = "figures/boxplot_aspect_ns.png", boxplot_aspect_ns, width = 15,height = 10, units = "cm", device = "png")
```

```{r}
# Compare non-parametric alternatives simple models

AICc(ts_lm_elevation_s, ts_lm_latitude_s, ts_lm_distance_sea_s)
```

### 4. Check slope change. Complex models:

```{r}
# check correlation between explanatory variables
data_collinearity <- data_models_significant %>% 
  select(c(elevation, latitude, distance_to_sea_corrected))
(pairs(data_collinearity))

cor(data_collinearity)
```

We can see a bit of correlation between elevation and distance to sea

```{r}
# elevation and latitude

# see if slope changes with elevation (interaction)
lm_elevation_latitude_int_s <- lm(slope ~ elevation * latitude, data = data_models_significant )
summary(lm_elevation_latitude_int_s)

# see if slope changes with elevation (no interaction)--> ecologically makes more sense no interaction
lm_elevation_latitude_s <- lm(slope ~ elevation + latitude, data = data_models_significant )
summary(lm_elevation_latitude_s)


# Check if model fits
elevation_latitude_resids_s <- resid(lm_elevation_latitude_s)
shapiro.test(elevation_latitude_resids_s)

check_model(lm_elevation_latitude_s)

# Non-parametric alternative --> which one?
#ts_lm_elevation_latitude_s <- mblm(slope ~ elevation + latitude ,data = data_models_significant)
#summary(ts_lm_elevation_s)

# Export

# Linear model summary and p-value formatting
model_summary_elevation_latitude_s <- tidy(lm_elevation_latitude_s) %>%
  mutate(
    p.value = case_when(
      p.value < 0.001 ~ paste0(format.pval(p.value, digits = 3), " ***"),
      p.value < 0.01 ~ paste0(format.pval(p.value, digits = 3), " **"),
      p.value < 0.05 ~ paste0(format.pval(p.value, digits = 3), " *"),
      TRUE ~ format.pval(p.value, digits = 3)
    )
  ) %>%
  rename(
    Term = term,
    Estimate = estimate,
    `Standard Error` = std.error,
    `t-Value` = statistic,
    `P-Value` = p.value
  ) 

# Display the table
model_summary_elevation_latitude_s %>%
  kbl(digits = 4) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

# Save as Excel file
write.xlsx(model_summary_elevation_latitude_s, "model_summary_elevation_latitude_s.xlsx")
```

Both are significant and explains 15.8% of change

```{r}
# elevation and distance to sea

# see if slope changes with elevation (interaction)
lm_elevation_ds_int_s <- lm(slope ~ distance_to_sea_corrected * elevation, data = data_models_significant)
summary(lm_elevation_ds_int_s)

# see if slope changes with elevation (no interaction)--> interaction is not significant
lm_elevation_ds_s <- lm(slope ~ distance_to_sea_corrected + elevation, data = data_models_significant )
summary(lm_elevation_ds_s)

# Check if model fits
elevation_ds_resids_s <- resid(lm_elevation_ds_s)
shapiro.test(elevation_ds_resids_s)

check_model(lm_elevation_ds_s)

# Non-parametric alternative --> which one?
#ts_lm_elevation_latitude_s <- mblm(slope ~ elevation + latitude ,data = data_models_significant)
#summary(ts_lm_elevation_s)

# Export

# Linear model summary and p-value formatting
model_summary_elevation_ds <- tidy(lm_elevation_ds_s) %>%
  mutate(
    p.value = case_when(
      p.value < 0.001 ~ paste0(format.pval(p.value, digits = 3), " ***"),
      p.value < 0.01 ~ paste0(format.pval(p.value, digits = 3), " **"),
      p.value < 0.05 ~ paste0(format.pval(p.value, digits = 3), " *"),
      TRUE ~ format.pval(p.value, digits = 3)
    )
  ) %>%
  rename(
    Term = term,
    Estimate = estimate,
    `Standard Error` = std.error,
    `t-Value` = statistic,
    `P-Value` = p.value
  ) 

# Display the table
model_summary_elevation_ds %>%
  kbl(digits = 4) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

# Save as Excel file
write.xlsx(model_summary_elevation_ds, "model_summary_elevation_ds.xlsx")
```

Explains 13% of change Distance to sea stops being significant --\> it
is very correlated with elevation

```{r}
# latitude and distance to sea

# see if slope changes with latitude (interaction)
lm_latitude_ds_int_s <- lm(slope ~ distance_to_sea_corrected * latitude, data = data_models_significant)
summary(lm_latitude_ds_int_s)
# no significnat interaction

# see if slope changes with latitude (no interaction)--> interaction is not significant
lm_latitude_ds_s <- lm(slope ~ distance_to_sea_corrected + latitude, data = data_models_significant )
summary(lm_latitude_ds_s)

# Check if model fits
latitude_ds_resids_s <- resid(lm_latitude_ds_s)
shapiro.test(latitude_ds_resids_s)

check_model(lm_latitude_ds_s)

# Non-parametric alternative --> which one?
#ts_lm_elevation_latitude_s <- mblm(slope ~ elevation + latitude ,data = data_models_significant)
#summary(ts_lm_elevation_s)

# Export

# Linear model summary and p-value formatting
model_summary_latitude_ds <- tidy(lm_latitude_ds_s) %>%
  mutate(
    p.value = case_when(
      p.value < 0.001 ~ paste0(format.pval(p.value, digits = 3), " ***"),
      p.value < 0.01 ~ paste0(format.pval(p.value, digits = 3), " **"),
      p.value < 0.05 ~ paste0(format.pval(p.value, digits = 3), " *"),
      TRUE ~ format.pval(p.value, digits = 3)
    )
  ) %>%
  rename(
    Term = term,
    Estimate = estimate,
    `Standard Error` = std.error,
    `t-Value` = statistic,
    `P-Value` = p.value
  ) 

# Display the table
model_summary_latitude_ds %>%
  kbl(digits = 4) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

# Save as Excel file
write.xlsx(model_summary_latitude_ds, "model_summary_latitude_ds.xlsx")
```

Distance to sea losses all of its effect as well. Not significant
anymore. teh effect must be taken by the small correlation. Explains 5 %

```{r}
# the three explanatory variables: latitude, altitude and distance to sea

# see if slope changes with latitude (interaction)
lm_latitude_elevation_ds_int_s <- lm(slope ~ distance_to_sea_corrected *latitude * elevation, data = data_models_significant)
summary(lm_latitude_elevation_ds_int_s)

# no significant interaction

# see if slope changes with latitude (no interaction)--> interaction is not significant
lm_latitude_elevation_ds_s <- lm(slope ~ distance_to_sea_corrected + latitude + elevation, data = data_models_significant)

summary(lm_latitude_elevation_ds_s)

# Check if model fits
latitude_ds_resids_s <- resid(lm_latitude_elevation_ds_int_s)
shapiro.test(latitude_ds_resids_s)

check_model(lm_latitude_elevation_ds_int_s)


check_model(lm_latitude_elevation_ds_s)
```

```{r}

## Check random interactions
# see if slope changes with latitude (interaction)
lm_latitude_elevation_ds_int_s_2 <- lm(slope ~ distance_to_sea_corrected + latitude * elevation, data = data_models_significant)
summary(lm_latitude_elevation_ds_int_s_2)

check_model(lm_latitude_elevation_ds_int_s_2)

# see if slope changes with latitude (interaction)
lm_latitude_elevation_ds_int_s_3 <- lm(slope ~ distance_to_sea_corrected * latitude + elevation, data = data_models_significant)
summary(lm_latitude_elevation_ds_int_s_3)

check_model(lm_latitude_elevation_ds_int_s_3)

# see if slope changes with latitude (interaction)
lm_latitude_elevation_ds_int_s_4 <- lm(slope ~ distance_to_sea_corrected * elevation + latitude, data = data_models_significant)
summary(lm_latitude_elevation_ds_int_s_4)

check_model(lm_latitude_elevation_ds_int_s_4)

# Export

# Linear model summary and p-value formatting
model_summary_latitude_elevation_ds_int <- tidy(lm_latitude_elevation_ds_int_s_4) %>%
  mutate(
    p.value = case_when(
      p.value < 0.001 ~ paste0(format.pval(p.value, digits = 3), " ***"),
      p.value < 0.01 ~ paste0(format.pval(p.value, digits = 3), " **"),
      p.value < 0.05 ~ paste0(format.pval(p.value, digits = 3), " *"),
      TRUE ~ format.pval(p.value, digits = 3)
    )
  ) %>%
  rename(
    Term = term,
    Estimate = estimate,
    `Standard Error` = std.error,
    `t-Value` = statistic,
    `P-Value` = p.value
  ) 

# Display the table
model_summary_latitude_elevation_ds_int %>%
  kbl(digits = 4) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

# Save as Excel file
write.xlsx(model_summary_latitude_elevation_ds_int, "model_summary_latitude_elevation_ds_int.xlsx")

```

Best explanation is all with interaction, but might be overfitted
according to check model. The best is therefore the model with latitude
and elevation without interaction.

## 10th Jan - Add NDVI as a covariance

```{r}
# Calculate mean, min and max NDVI 
data_mean_NDVI <- data_NDVI_predictions_clean %>%
  group_by(latitude, longitude) %>% 
  summarise (mean_NDVI = mean(NDVI),
             min_NDVI = min(NDVI),
             max_NDVI = max(NDVI))


# Add to dataset
data_models_significant<- inner_join(data_models_significant,data_mean_NDVI, by = c("latitude", "longitude"))

```

Add as a covariance

```{r}
# see if slope changes with elevation
lm_mean_s <- lm(slope ~ mean_NDVI, data = data_models_significant )
summary(lm_mean_s)


# Check if model fits
slope_mean_s <- resid(lm_mean_s)
shapiro.test(slope_mean_s)

check_model(lm_mean_s)

```

Significant--\> green places tend to become greener

Add in larger models

### 4. Check slope change. Complex models:

```{r}
# check correlation between explanatory variables
data_collinearity <- data_models_significant %>% 
  select(c(elevation, latitude, distance_to_sea_corrected, mean_NDVI, min_NDVI))
(pairs(data_collinearity))

cor(data_collinearity)
```

Doesn't seem to be correlation between mean NDVI and any other variable
except min NDVI

### **The model**

```{r}
# elevation and mean NDVI

# see if slope changes with elevation (interaction)
lm_elevation_mean_int_s <- lm(slope ~ elevation * mean_NDVI, data = data_models_significant )
summary(lm_elevation_mean_int_s)

# see if slope changes with elevation (no interaction)--> ecologically makes more sense no interaction
lm_elevation_mean_s <- lm(slope ~ elevation + mean_NDVI, data = data_models_significant )
summary(lm_elevation_mean_s)


# Check if model fits
elevation_mean_resids_int_s <- resid(lm_elevation_mean_int_s)
shapiro.test(elevation_mean_resids_int_s)

check_model(lm_elevation_mean_int_s)
```

There is a significant interaction--\> when the interaction happens mean
NDVI is not significant anymore.Explains 25.63% of the model The effect
of elevation depends on the mean NDVi/initial level of greeness The
model with interaction explains more

```{r}
# export table

model_summary <- tidy(lm_elevation_mean_int_s) %>%
  mutate(p.value = format.pval(p.value, digits = 3))  # Format p-values for readability

model_summary <- tidy(lm_elevation_mean_int_s) %>%
  mutate(
    p.value = case_when(
      p.value < 0.001 ~ paste0(format.pval(p.value, digits = 3), " ***"),
      p.value < 0.01 ~ paste0(format.pval(p.value, digits = 3), " **"),
      p.value < 0.05 ~ paste0(format.pval(p.value, digits = 3), " *"),
      TRUE ~ format.pval(p.value, digits = 3)
    )  # Add stars directly to p-value column
  )

(model_sumamry <- model_summary %>%
  rename(
    Term = term,
    Estimate = estimate,
    `Standard Error` = std.error,
    `t-Value` = statistic,
    `P-Value` = p.value
  ) %>%
  kbl(digits = 4) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")))


write.xlsx(model_summary, "model_summary_table_elevation_ndvi.xlsx")  # Save as an Excel file
```

```{r}
# latitude and mean NDVI

# see if slope changes with elevation (interaction)
lm_latitude_mean_int_s <- lm(slope ~ latitude * mean_NDVI, data = data_models_significant )
summary(lm_latitude_mean_int_s)

# see if slope changes with elevation (no interaction)--> ecologically makes more sense no interaction
lm_latitude_mean_s <- lm(slope ~ latitude + mean_NDVI, data = data_models_significant )
summary(lm_latitude_mean_s)


# Check if model fits
latitude_mean_resids_int_s <- resid(lm_latitude_mean_int_s)
shapiro.test(latitude_mean_resids_int_s)

check_model(lm_latitude_mean_s)

# Export

# Linear model summary and p-value formatting
model_summary_lat_meanndvi <- tidy(lm_latitude_mean_s) %>%
  mutate(
    p.value = case_when(
      p.value < 0.001 ~ paste0(format.pval(p.value, digits = 3), " ***"),
      p.value < 0.01 ~ paste0(format.pval(p.value, digits = 3), " **"),
      p.value < 0.05 ~ paste0(format.pval(p.value, digits = 3), " *"),
      TRUE ~ format.pval(p.value, digits = 3)
    )
  ) %>%
  rename(
    Term = term,
    Estimate = estimate,
    `Standard Error` = std.error,
    `t-Value` = statistic,
    `P-Value` = p.value
  ) 

# Display the table
model_summary_lat_meanndvi %>%
  kbl(digits = 4) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

# Save as Excel file
write.xlsx(model_summary_lat_meanndvi, "model_summary_lat_meanndvi.xlsx")
```

There is no significant interaction. In the no interaction model
mean_NDVI is significant, but latitude isn't--\> latitude has an effect
most likely because at higher latitude there is lower mean NDVI --\>
check

```{r}
# see if NDVI changes with latitude
lm_latitude_mean_s <- lm(mean_NDVI ~ latitude, data = data_models_significant )
summary(lm_latitude_mean_s)

# Check if model fits
latitude_mean_resids_s <- resid(lm_latitude_mean_s)
shapiro.test(latitude_mean_resids_s)

check_model(lm_latitude_mean_s)
# terrible fit--> try non-parametrical

# Non-parametric alternative --> Theil-Sen
ts_lm_mean_latitude_s <- mblm(mean_NDVI ~ latitude, data = data_models_significant)
summary(ts_lm_mean_latitude_s)
```

yes. It changes

```{r}
# see if NDVI changes with aspect
# 4 aspects
lm_aspect_mean_s <- lm(mean_NDVI ~ aspect, data = data_models_significant )
summary(lm_aspect_mean_s)
anova(lm_aspect_mean_s)

data_north_south_significant <- data_models_significant %>% 
  filter(aspect %in% c("north", "south"))

# 2 aspects
lm_aspect_ns_mean_s <- lm(mean_NDVI ~ aspect, data = data_north_south_significant )
summary(lm_aspect_ns_mean_s)
anova(lm_aspect_ns_mean_s)


```


```{r}
# distance to sea and mean NDVI

# see if slope changes with distance to sea (interaction)
lm_ds_mean_int_s <- lm(slope ~ distance_to_sea_corrected * mean_NDVI, data = data_models_significant )
summary(lm_ds_mean_int_s)

# see if slope changes with distance to sea (no interaction)--> ecologically makes more sense no interaction
lm_ds_mean_s <- lm(slope ~ distance_to_sea_corrected + mean_NDVI, data = data_models_significant )
summary(lm_ds_mean_s)


# Check if model fits
ds_mean_resids_int_s <- resid(lm_ds_mean_int_s)
shapiro.test(ds_mean_resids_int_s)

check_model(lm_ds_mean_int_s)


# Export

# Linear model summary and p-value formatting
model_summary_ds_mean <- tidy(lm_ds_mean_int_s) %>%
  mutate(
    p.value = case_when(
      p.value < 0.001 ~ paste0(format.pval(p.value, digits = 3), " ***"),
      p.value < 0.01 ~ paste0(format.pval(p.value, digits = 3), " **"),
      p.value < 0.05 ~ paste0(format.pval(p.value, digits = 3), " *"),
      TRUE ~ format.pval(p.value, digits = 3)
    )
  ) %>%
  rename(
    Term = term,
    Estimate = estimate,
    `Standard Error` = std.error,
    `t-Value` = statistic,
    `P-Value` = p.value
  ) 

# Display the table
model_summary_ds_mean %>%
  kbl(digits = 4) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

# Save as Excel file
write.xlsx(model_summary_ds_mean, "model_summary_ds_mean.xlsx")
```

there is an interaction. When teh intercayion is significant the effect
of mean NDVI is not significnat.Same as with elevation (probably due to
the interaction between distance to sea and elevation). Explains 22.59%
--\> a little less than elevation

```{r}
# the three explanatory variables: latitude, altitude and mean_NDVI

# see if slope changes with latitude (interaction)
lm_latitude_elevation_mean_int_s <- lm(slope ~ mean_NDVI *latitude * elevation, data = data_models_significant)
summary(lm_latitude_elevation_mean_int_s) # overfitted

# no significant interaction

# see if slope changes with latitude (no interaction)--> interaction is not significant
lm_latitude_elevation_mean_s <- lm(slope ~ mean_NDVI + latitude + elevation, data = data_models_significant)

summary(lm_latitude_elevation_ds_s) # explains less

# see if slope changes with latitude (no interaction)--> interaction is not significant
lm_latitude_elevation_mean_s_2 <- lm(slope ~ mean_NDVI * elevation + latitude, data = data_models_significant)

summary(lm_latitude_elevation_mean_s_2) # explains less than without latitude

# Check if model fits

check_model(lm_latitude_elevation_mean_int_s)


check_model(lm_latitude_elevation_mean_s)

check_model(lm_latitude_elevation_mean_s_2)

# Export

# Linear model summary and p-value formatting
model_summary_lat_elev_mean <- tidy(lm_latitude_elevation_mean_s_2) %>%
  mutate(
    p.value = case_when(
      p.value < 0.001 ~ paste0(format.pval(p.value, digits = 3), " ***"),
      p.value < 0.01 ~ paste0(format.pval(p.value, digits = 3), " **"),
      p.value < 0.05 ~ paste0(format.pval(p.value, digits = 3), " *"),
      TRUE ~ format.pval(p.value, digits = 3)
    )
  ) %>%
  rename(
    Term = term,
    Estimate = estimate,
    `Standard Error` = std.error,
    `t-Value` = statistic,
    `P-Value` = p.value
  ) 

# Display the table
model_summary_ds_mean %>%
  kbl(digits = 4) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

# Save as Excel file
write.xlsx(model_summary_lat_elev_mean, "model_summary_lat_elev_mean.xlsx")
```

```{r}
# 4 variables model
lm_latitude_elevation_mean_ds_int_s <- lm(slope ~ elevation * mean_NDVI +distance_to_sea_corrected + latitude , data = data_models_significant)

summary(lm_latitude_elevation_mean_ds_int_s)# explains less

check_model(lm_latitude_elevation_mean_ds_int_s)


# Export

# Linear model summary and p-value formatting
model_summary_latitude_elevation_mean_ds_int <- tidy(lm_latitude_elevation_mean_ds_int_s) %>%
  mutate(
    p.value = case_when(
      p.value < 0.001 ~ paste0(format.pval(p.value, digits = 3), " ***"),
      p.value < 0.01 ~ paste0(format.pval(p.value, digits = 3), " **"),
      p.value < 0.05 ~ paste0(format.pval(p.value, digits = 3), " *"),
      TRUE ~ format.pval(p.value, digits = 3)
    )
  ) %>%
  rename(
    Term = term,
    Estimate = estimate,
    `Standard Error` = std.error,
    `t-Value` = statistic,
    `P-Value` = p.value
  ) 

# Display the table
model_summary_latitude_elevation_mean_ds_int %>%
  kbl(digits = 4) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

# Save as Excel file
write.xlsx(model_summary_latitude_elevation_mean_ds_int, "model_summary_latitude_elevation_mean_ds_int.xlsx")
```

The best model is elevation, mean_NDVI with interaction. Mean_NDVI has a
very strong correlation with latitude. Even though the topographical
variables affecting it are latitude and elevation. Latitude affecst
because mean NDVI affects, and the effect of elevation depends on the
initial starting point.

## PLOTS

```{r}
# Generate predictions for a grid
elevation_vals <- seq(min(data_models_significant$elevation), max(data_models_significant$elevation), length.out = 100)

ndvi_vals <- seq(min(data_models_significant$mean_NDVI), max(data_models_significant$mean_NDVI), length.out = 5)
ndvi_vals <- round(ndvi_vals, digits = 3)

grid <- expand.grid(elevation = elevation_vals, mean_NDVI = ndvi_vals)
predictions <- predict(lm_elevation_mean_int_s, newdata = grid, interval = "confidence")
grid$slope <- predictions[, "fit"]         # Predicted slope
grid$lower <- predictions[, "lwr"]         # Lower bound of confidence interval
grid$upper <- predictions[, "upr"]         # Upper bound of confidence interval

# Contour plot
(lm_plot <- ggplot(grid, aes(x = elevation, y = slope, color = as.factor(mean_NDVI))) +
   geom_ribbon(aes(ymin = lower, ymax = upper, fill = as.factor(mean_NDVI)), alpha = 0.2, color = NA, show.legend = FALSE) +
  geom_line(size = 1) +
  labs(x = "Elevation",
       y = "Slope of the trend",
       color = "Mean NDVI") +
  theme_classic()+
  theme(
    axis.title = element_text(size = 14, face = "bold"),  # Larger and bold axis titles
    axis.text = element_text(size = 12),                 # Larger axis text
    legend.title = element_text(size = 14, face = "bold"), # Larger and bold legend title
    legend.text = element_text(size = 12)                # Larger legend text
  ))

# Save graph
ggsave(filename = "figures/lm_plot.png", lm_plot, width = 20,height = 15, units = "cm", device = "png")
```

```{r}
library(effects)

# Plot interaction effects
plot(allEffects(lm_elevation_mean_int_s), multiline = TRUE, main = "Interaction: Elevation x Mean NDVI")
```

```{r}
# Create NDVI quantiles
data_models_significant <- data_models_significant %>%
  mutate(NDVI_quantile = ntile(mean_NDVI, 4))

# Plot faceted lines
ggplot(data_models_significant, aes(x = elevation, y = slope, color = as.factor(NDVI_quantile))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~ NDVI_quantile, labeller = label_both) +
  labs(title = "Slope vs Elevation across NDVI Quantiles",
       x = "Elevation",
       y = "Slope",
       color = "NDVI Quantile") +
  theme_minimal()
```
